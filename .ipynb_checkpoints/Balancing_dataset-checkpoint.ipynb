{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4da50cc",
   "metadata": {},
   "source": [
    "# ML stroke prediction - Logistic Regression\n",
    "dataset link: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset?resource=download\n",
    "\n",
    "## Classification of stroke or no-stroke\n",
    "\n",
    "For the first implementation of Machine Learning on this dataset we are using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f961d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import logistic_regression as lr\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "# SKlearn for F1 score calculation\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# we use pandas to import a comma-seperated values dataset\n",
    "import pandas as pd\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2695bf3",
   "metadata": {},
   "source": [
    "### First importing the dataset and small conversions\n",
    "\n",
    "For the first implementation we're just using a limited set of features for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7cd6fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  hypertension  heart_disease  avg_glucose_level  stroke\n",
      "0     67.0             0              1             228.69       1\n",
      "1     61.0             0              0             202.21       1\n",
      "2     80.0             0              1             105.92       1\n",
      "3     49.0             0              0             171.23       1\n",
      "4     79.0             1              0             174.12       1\n",
      "...    ...           ...            ...                ...     ...\n",
      "5105  80.0             1              0              83.75       0\n",
      "5106  81.0             0              0             125.20       0\n",
      "5107  35.0             0              0              82.99       0\n",
      "5108  51.0             0              0             166.29       0\n",
      "5109  44.0             0              0              85.28       0\n",
      "\n",
      "[5110 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#  training data stored in arrays X, y\n",
    "#df = pd.read_csv(os.path.join('data', 'healthcare-dataset-stroke-data.csv'))\n",
    "#X = pd.DataFrame(df, columns=['age', 'hypertension', 'heart_disease', 'avg_glucose_level']).to_numpy()\n",
    "#X = np.around(X, 5)\n",
    "#print(\"X: \")\n",
    "#print(X)\n",
    "\n",
    "#y = pd.DataFrame(df, columns=['stroke']).to_numpy()\n",
    "#y = np.around(y, 5)\n",
    "#y.reshape(5110)\n",
    "#print(\"y: \")\n",
    "#print(y)\n",
    " \n",
    "data = pd.read_csv(os.path.join('data', 'healthcare-dataset-stroke-data.csv'))\n",
    "\n",
    "data.head(10)\n",
    "\n",
    "data.drop(\"id\", axis = 1, inplace = True)\n",
    "data.drop(\"gender\", axis = 1, inplace = True)\n",
    "data.drop(\"ever_married\", axis = 1, inplace = True)\n",
    "data.drop(\"work_type\", axis = 1, inplace = True)\n",
    "data.drop(\"Residence_type\", axis = 1, inplace = True)\n",
    "data.drop(\"bmi\", axis = 1, inplace = True)\n",
    "data.drop(\"smoking_status\", axis = 1, inplace = True)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0e72e",
   "metadata": {},
   "source": [
    "The sigmoid function copied from excersise 2. Could be copied later on to a 'library'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f215fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59.     0.     0.   200.62   1.  ]\n",
      " [ 70.     1.     0.   242.52   1.  ]\n",
      " [ 69.     0.     0.    93.81   1.  ]\n",
      " [ 79.     0.     0.   114.77   1.  ]\n",
      " [  3.     0.     0.    95.12   0.  ]\n",
      " [ 58.     1.     0.    87.96   0.  ]\n",
      " [  8.     0.     0.   110.89   0.  ]\n",
      " [ 70.     0.     0.    69.04   0.  ]\n",
      " [ 14.     0.     0.   161.28   0.  ]\n",
      " [ 47.     0.     0.   210.95   0.  ]]\n",
      "199\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "counter_stroke = 0\n",
    "counter_non_stroke = 0\n",
    "data_balanced = np.zeros((398,5))\n",
    "#print(data_balanced.shape)\n",
    "data_balanced[0:199] = data[0:199]\n",
    "data_balanced[199:398] = data[249:448]\n",
    "print(data_balanced[195:205])\n",
    "for i in range(398):\n",
    "    if data_balanced[i, 4] == 1:\n",
    "        counter_stroke += 1\n",
    "    else:\n",
    "        counter_non_stroke += 1\n",
    "        \n",
    "print(counter_stroke)\n",
    "print(counter_non_stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233cdeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xshape: \n",
      "(5110, 4)\n",
      "Yshape: \n",
      "(5110,)\n",
      "X: \n",
      "[[ 67.     0.     1.   228.69]\n",
      " [ 61.     0.     0.   202.21]\n",
      " [ 80.     0.     1.   105.92]\n",
      " ...\n",
      " [ 35.     0.     0.    82.99]\n",
      " [ 51.     0.     0.   166.29]\n",
      " [ 44.     0.     0.    85.28]]\n",
      "y: \n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['stroke'], axis=1).values\n",
    "y = data['stroke'].values\n",
    "\n",
    "print(\"Xshape: \")\n",
    "print(X.shape)\n",
    "print(\"Yshape: \")\n",
    "print(y.shape)\n",
    "\n",
    "print(\"X: \")\n",
    "print(X)\n",
    "\n",
    "print(\"y: \")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b090a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4861\n",
      "1    4861\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "negative = data[data.stroke==0]\n",
    "positive = data[data.stroke==1]\n",
    "\n",
    "#print(data.stroke.value_counts())\n",
    "\n",
    "#print(negative.stroke.value_counts())\n",
    "#print(positive.stroke.value_counts())\n",
    "\n",
    "# upsample minority\n",
    "pos_upsampled = resample(positive,\n",
    " replace=True, # sample with replacement\n",
    " n_samples=len(negative), # match number in majority class\n",
    " random_state=27) # reproducible results\n",
    "\n",
    "upsampled = pd.concat([negative, pos_upsampled])\n",
    "\n",
    "print(upsampled.stroke.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0484ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = upsampled.drop(['stroke'], axis=1).values\n",
    "y = upsampled['stroke'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832fbc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9722, 4)\n",
      "(9722, 5)\n"
     ]
    }
   ],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = X.shape\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "print(X.shape)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0952db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c98677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at test theta: 0.693\n",
      "Gradient at test theta:\n",
      "\t[0.000, -6.372, -0.042, -0.036, -6.820]\n"
     ]
    }
   ],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros(n+1)\n",
    "cost, grad = lr.lrCostFunction(initial_theta, X, y, _lambda)\n",
    "#print(cost)\n",
    "#print(grad)\n",
    "\n",
    "#print(cost.shape)\n",
    "#print(grad.shape)\n",
    "\n",
    "print('Cost at test theta: {:.3f}'.format(cost))\n",
    "\n",
    "print('Gradient at test theta:')\n",
    "print('\\t[{:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}]'.format(*grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6178ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta found by optimize.minimize: 0.486\n",
      "theta:\n",
      "\t[-4.651, 0.071, 0.431, 0.422, 0.004]\n"
     ]
    }
   ],
   "source": [
    "theta, cost, grad = lr.lrOptimization(lr.lrCostFunction, initial_theta, X, y, _lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593e9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 76.26 %\n"
     ]
    }
   ],
   "source": [
    "p = lr.predict(theta, X, 0.35)\n",
    "print('Train Accuracy: {:.2f} %'.format(np.mean(p == y) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec8e1641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7952085181898846\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y,p,average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f810cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeker:  0.3\n",
      "0.7842456840461525\n",
      "zeker:  0.31\n",
      "0.7871136264693077\n",
      "zeker:  0.32\n",
      "0.7893128437963853\n",
      "zeker:  0.33\n",
      "0.7905832747716093\n",
      "zeker:  0.34\n",
      "0.7919059821507467\n",
      "zeker:  0.35\n",
      "0.7952085181898846\n",
      "zeker:  0.36\n",
      "0.7937444146559428\n",
      "zeker:  0.37\n",
      "0.793016558675306\n",
      "zeker:  0.38\n",
      "0.793947082276187\n",
      "zeker:  0.39\n",
      "0.7917770671539515\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 40):\n",
    "    p = lr.predict(theta, X, (i/100))\n",
    "    print(\"zeker: \", i/100)\n",
    "    print(f1_score(y,p,average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504be39",
   "metadata": {},
   "source": [
    "# Oversampling werkt!!!!\n",
    "\n",
    "### Dit is zonder train test split\n",
    "\n",
    "### Hieronder met undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7ddd9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    249\n",
       "0    249\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = data[data.stroke==0]\n",
    "positive = data[data.stroke==1]\n",
    "\n",
    "#print(data.stroke.value_counts())\n",
    "\n",
    "#print(negative.stroke.value_counts())\n",
    "#print(positive.stroke.value_counts())\n",
    "\n",
    "# downsample majority\n",
    "neg_downsampled = resample(negative,\n",
    " replace=True, # sample with replacement\n",
    " n_samples=len(positive), # match number in minority class\n",
    " random_state=27) # reproducible results\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([positive, neg_downsampled])\n",
    "# check new class counts\n",
    "downsampled.stroke.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "611c38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = downsampled.drop(['stroke'], axis=1).values\n",
    "y = downsampled['stroke'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7bcf30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 4)\n",
      "(498, 5)\n"
     ]
    }
   ],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = X.shape\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "print(X.shape)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b33d611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at test theta: 0.693\n",
      "Gradient at test theta:\n",
      "\t[0.000, -6.855, -0.052, -0.036, -7.120]\n"
     ]
    }
   ],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros(n+1)\n",
    "cost, grad = lr.lrCostFunction(initial_theta, X, y, _lambda)\n",
    "#print(cost)\n",
    "#print(grad)\n",
    "\n",
    "#print(cost.shape)\n",
    "#print(grad.shape)\n",
    "\n",
    "print('Cost at test theta: {:.3f}'.format(cost))\n",
    "\n",
    "print('Gradient at test theta:')\n",
    "print('\\t[{:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}]'.format(*grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4fb41c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta found by optimize.minimize: 0.460\n",
      "theta:\n",
      "\t[-4.907, 0.074, 0.768, 0.165, 0.005]\n"
     ]
    }
   ],
   "source": [
    "theta, cost, grad = lr.lrOptimization(lr.lrCostFunction, initial_theta, X, y, _lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d59f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 78.92 %\n"
     ]
    }
   ],
   "source": [
    "p = lr.predict(theta, X, 0.39)\n",
    "print('Train Accuracy: {:.2f} %'.format(np.mean(p == y) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e21c6d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8134991119005329\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y,p,average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af43a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeker:  0.3\n",
      "0.7986230636833047\n",
      "zeker:  0.31\n",
      "0.8\n",
      "zeker:  0.32\n",
      "0.8027681660899654\n",
      "zeker:  0.33\n",
      "0.8076923076923077\n",
      "zeker:  0.34\n",
      "0.8141592920353982\n",
      "zeker:  0.35\n",
      "0.8134991119005329\n",
      "zeker:  0.36\n",
      "0.8142857142857142\n",
      "zeker:  0.37\n",
      "0.8144144144144144\n",
      "zeker:  0.38\n",
      "0.8144144144144144\n",
      "zeker:  0.39\n",
      "0.8152173913043479\n",
      "zeker:  0.4\n",
      "0.8087431693989071\n",
      "zeker:  0.41\n",
      "0.8073394495412842\n",
      "zeker:  0.42\n",
      "0.8081180811808116\n",
      "zeker:  0.43\n",
      "0.8037037037037037\n",
      "zeker:  0.44\n",
      "0.8\n",
      "zeker:  0.45\n",
      "0.8\n",
      "zeker:  0.46\n",
      "0.799249530956848\n",
      "zeker:  0.47\n",
      "0.7954545454545455\n",
      "zeker:  0.48\n",
      "0.793168880455408\n",
      "zeker:  0.49\n",
      "0.7892720306513409\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 50):\n",
    "    p = lr.predict(theta, X, (i/100))\n",
    "    print(\"zeker: \", i/100)\n",
    "    print(f1_score(y,p,average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e37219",
   "metadata": {},
   "source": [
    "# Undersampling werkt!!!\n",
    "### Dit heeft een beter resultaat als oversampling\n",
    "### Op de trainingset, the real test is met de testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ead312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
