{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4da50cc",
   "metadata": {},
   "source": [
    "# ML stroke prediction - Logistic Regression\n",
    "dataset link: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset?resource=download\n",
    "\n",
    "## Classification of stroke or no-stroke\n",
    "\n",
    "For the first implementation of Machine Learning on this dataset we are using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f961d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import logistic_regression as lr\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "# SKlearn for F1 score calculation\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# we use pandas to import a comma-seperated values dataset\n",
    "import pandas as pd\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2695bf3",
   "metadata": {},
   "source": [
    "### First importing the dataset and small conversions\n",
    "\n",
    "For the first implementation we're just using a limited set of features for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7cd6fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  hypertension  heart_disease  avg_glucose_level  stroke\n",
      "0     67.0             0              1             228.69       1\n",
      "1     61.0             0              0             202.21       1\n",
      "2     80.0             0              1             105.92       1\n",
      "3     49.0             0              0             171.23       1\n",
      "4     79.0             1              0             174.12       1\n",
      "...    ...           ...            ...                ...     ...\n",
      "5105  80.0             1              0              83.75       0\n",
      "5106  81.0             0              0             125.20       0\n",
      "5107  35.0             0              0              82.99       0\n",
      "5108  51.0             0              0             166.29       0\n",
      "5109  44.0             0              0              85.28       0\n",
      "\n",
      "[5110 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#  training data stored in arrays X, y\n",
    "#df = pd.read_csv(os.path.join('data', 'healthcare-dataset-stroke-data.csv'))\n",
    "#X = pd.DataFrame(df, columns=['age', 'hypertension', 'heart_disease', 'avg_glucose_level']).to_numpy()\n",
    "#X = np.around(X, 5)\n",
    "#print(\"X: \")\n",
    "#print(X)\n",
    "\n",
    "#y = pd.DataFrame(df, columns=['stroke']).to_numpy()\n",
    "#y = np.around(y, 5)\n",
    "#y.reshape(5110)\n",
    "#print(\"y: \")\n",
    "#print(y)\n",
    " \n",
    "data = pd.read_csv(os.path.join('data', 'healthcare-dataset-stroke-data.csv'))\n",
    "\n",
    "data.head(10)\n",
    "\n",
    "data.drop(\"id\", axis = 1, inplace = True)\n",
    "data.drop(\"gender\", axis = 1, inplace = True)\n",
    "data.drop(\"ever_married\", axis = 1, inplace = True)\n",
    "data.drop(\"work_type\", axis = 1, inplace = True)\n",
    "data.drop(\"Residence_type\", axis = 1, inplace = True)\n",
    "data.drop(\"bmi\", axis = 1, inplace = True)\n",
    "data.drop(\"smoking_status\", axis = 1, inplace = True)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148f167",
   "metadata": {},
   "source": [
    "# Downsampling of the dataset before split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a785b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    249\n",
       "0    249\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = data[data.stroke==0]\n",
    "positive = data[data.stroke==1]\n",
    "\n",
    "#print(data.stroke.value_counts())\n",
    "\n",
    "#print(negative.stroke.value_counts())\n",
    "#print(positive.stroke.value_counts())\n",
    "\n",
    "# downsample majority\n",
    "neg_downsampled = resample(negative,\n",
    " replace=True, # sample with replacement\n",
    " n_samples=len(positive), # match number in minority class\n",
    " random_state=27) # reproducible results\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([positive, neg_downsampled])\n",
    "# check new class counts\n",
    "downsampled.stroke.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea0626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = downsampled.drop(['stroke'], axis=1).values\n",
    "y = downsampled['stroke'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba43ce",
   "metadata": {},
   "source": [
    "# Splitting in train en test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df03ec5a",
   "metadata": {},
   "source": [
    "### preparation of the features\n",
    "Adding a theta 0 equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e06abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 4)\n",
      "(498, 5)\n"
     ]
    }
   ],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = X.shape\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# Add intercept term to X\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "print(X.shape)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a549ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0,shuffle=True, stratify=y)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad21fa7",
   "metadata": {},
   "source": [
    "# Hierboven maar 1x inladen !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8491dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fff23a",
   "metadata": {},
   "source": [
    "### Creating the empty array for theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b50e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros(n+1)\n",
    "cost, grad = lr.lrcostFunctionReg(initial_theta, X_train, y_train, _lambda)\n",
    "#print(cost)\n",
    "#print(grad)\n",
    "\n",
    "#print(cost.shape)\n",
    "#print(grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e47b5",
   "metadata": {},
   "source": [
    "### Optimizing the parameters (learning the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68968cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta found by optimize.minimize: 0.464\n",
      "theta:\n",
      "\t[-4.920, 0.072, 0.973, 0.116, 0.006]\n"
     ]
    }
   ],
   "source": [
    "theta, cost, grad = lr.lrOptimization(lr.lrcostFunctionReg, initial_theta, X_train, y_train, _lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16d20a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 78.89 %\n"
     ]
    }
   ],
   "source": [
    "p_train = lr.predict(theta, X_train, 0.39)\n",
    "print('Train Accuracy: {:.2f} %'.format(np.mean(p_train == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40adb801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op de training set\n",
      "0.8099547511312218\n"
     ]
    }
   ],
   "source": [
    "print(\"op de training set\")\n",
    "print(f1_score(y_train,p_train,average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d0fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeker:  0.3\n",
      "0.8034482758620689\n",
      "zeker:  0.31\n",
      "0.8034782608695652\n",
      "zeker:  0.32\n",
      "0.8105263157894735\n",
      "zeker:  0.33\n",
      "0.8134991119005329\n",
      "zeker:  0.34\n",
      "0.8128342245989305\n",
      "zeker:  0.35\n",
      "0.8144144144144144\n",
      "zeker:  0.36\n",
      "0.8158844765342961\n",
      "zeker:  0.37\n",
      "0.8152173913043479\n",
      "zeker:  0.38\n",
      "0.8130671506352087\n",
      "zeker:  0.39\n",
      "0.8138686131386861\n",
      "zeker:  0.4\n",
      "0.8044280442804428\n",
      "zeker:  0.41\n",
      "0.8059149722735675\n",
      "zeker:  0.42\n",
      "0.7992565055762081\n",
      "zeker:  0.43\n",
      "0.7947761194029851\n",
      "zeker:  0.44\n",
      "0.7954971857410882\n",
      "zeker:  0.45\n",
      "0.7947269303201507\n",
      "zeker:  0.46\n",
      "0.7916666666666667\n",
      "zeker:  0.47\n",
      "0.7900763358778626\n",
      "zeker:  0.48\n",
      "0.7892720306513409\n",
      "zeker:  0.49\n",
      "0.7846153846153846\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 50):\n",
    "    p = lr.predict(theta, X, (i/100))\n",
    "    print(\"zeker: \", i/100)\n",
    "    print(f1_score(y,p,average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee523e3",
   "metadata": {},
   "source": [
    "# F1 score op test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a86b163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op de test set\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "p_test = lr.predict(theta, X_test, 0.35)\n",
    "print(\"op de test set\")\n",
    "print(f1_score(y_test,p_test,average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51234691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(30, 50):\n",
    "#    p_test = lr.predict(theta, X_test, (i/100))\n",
    "#    print(\"zeker: \", i/100)\n",
    "#    print(f1_score(y_test,p_test,average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c514a04",
   "metadata": {},
   "source": [
    "## Beste score tot nu toe op de test set:\n",
    "## 83.3 voor een decision boundary van 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f63fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
